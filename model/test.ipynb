{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:11<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果你有任何问题或需要帮助,请随时告诉我。我很乐意为你提供帮助。\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "torch.cuda.set_device(2)\n",
    "torch.cuda.empty_cache()\n",
    "model = AutoModel.from_pretrained(\"THUDM/chatglm2-6b\", trust_remote_code=True).half().cuda()\n",
    "torch.cuda.empty_cache()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm2-6b\", trust_remote_code=True)\n",
    "\n",
    "model = model.eval()\n",
    "\n",
    "response, history = model.chat(tokenizer, \"你有什么要对我说的吗\", history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: goto-statement in /home/grammar/.local/lib/python3.9/site-packages (1.2)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install goto-statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句子本身没有明显的语法或语义错误,可以被视为健康的句子。\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"请判断如下句子是否是病句，如果是，请判断错误的类别并且返回修改后的结果。句子： 做科学上的事实判断，不同的人从不同的视角、不同的方式为出发点，终究可以获得一致的结论，达成某种程度的一致的意见。\", history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "jsonfile=open('resp.json','w',encoding='gb2312')\n",
    "count=1\n",
    "notwritten=[]\n",
    "with open('dataset.csv', 'r',encoding='gb2312') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        text=row[1]\n",
    "        # print(text)\n",
    "        with open('prompt.txt','r',encoding='utf-8')as f:\n",
    "            prompt=f.read()\n",
    "            # print(prompt)\n",
    "            prompt=prompt+f\"\\n#\\n{text}\\n#\"\n",
    "            # print(prompt)\n",
    "            response, history = model.chat(tokenizer, prompt, history=[])\n",
    "            # print(response)\n",
    "            try:\n",
    "                respjson=json.loads(response)\n",
    "                \n",
    "            except:\n",
    "                print('not written!')\n",
    "                notwritten.append(count)\n",
    "                pass\n",
    "            json.dump(respjson,jsonfile)\n",
    "            jsonfile.write(',')\n",
    "            print(count)\n",
    "            count+=1\n",
    "    jsonfile.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('resp.json','r',encoding='utf-8')as f:\n",
    "    data=json.load(f)\n",
    "with open('resp.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resp.csv','w',encoding='utf-8') as f:\n",
    "    writer=csv.writer(f)\n",
    "    writer.writerow(data[0].keys())\n",
    "    for item in data:\n",
    "        writer.writerow(item.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modify&test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "content=[]\n",
    "with open('resp.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    # print(type(reader))\n",
    "    header = next(reader) # 读取表头\n",
    "    num_fields = len(header) # 字段数目\n",
    "    content.append(header)\n",
    "    for row in reader:\n",
    "        # print(type(row))\n",
    "        if len(row) != num_fields:\n",
    "            print(f\"Error: Expected {num_fields} fields in line {reader.line_num}, saw {len(row)}\")\n",
    "            del row[2]\n",
    "            \n",
    "            print('line ',reader.line_num,'has been modified!')\n",
    "        row[0]=row[0].strip()\n",
    "        row[1]=row[1].strip()\n",
    "        row[2]=row[2].strip()\n",
    "        content.append(row)\n",
    "with open('resp.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'gb2312' codec can't decode byte 0xe5 in position 6: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m reader \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mreader(f)\n\u001b[1;32m      5\u001b[0m rows\u001b[39m=\u001b[39m[]\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m reader:\n\u001b[1;32m      7\u001b[0m     row[\u001b[39m1\u001b[39m]\u001b[39m=\u001b[39mrow[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m      8\u001b[0m     rows\u001b[39m.\u001b[39mappend(row)\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'gb2312' codec can't decode byte 0xe5 in position 6: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import csv\n",
    "with open('dataset.csv', 'r', encoding='gb2312') as f:\n",
    "    reader = csv.reader(f)\n",
    "    rows=[row for row in reader]\n",
    "\n",
    "with codecs.open('dataset.csv', 'w', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=[]\n",
    "with open('dataset.csv', 'r') as f:\n",
    "    reader=csv.reader(f)\n",
    "    for row in reader:\n",
    "        row[1]=row[1].strip()\n",
    "        row[2]=row[2].strip()\n",
    "        rows.append(row)\n",
    "with open('dataset.csv', 'w') as f:\n",
    "    writer= csv.writer(f)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     正确句子  \\\n",
      "0       做哲学上的价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同...   \n",
      "1       做哲学上的价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同...   \n",
      "2       做哲学上的价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同...   \n",
      "3       做哲学上的价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同...   \n",
      "4       做哲学上的价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同...   \n",
      "...                                                   ...   \n",
      "222609         \"[20]（p.39）但随着研究的不断深入，学者们得出的结论也逐渐趋向比较客观和公允   \n",
      "222610         \"[20]（p.39）但随着研究的不断深入，学者们得出的结论也逐渐趋向比较客观和公允   \n",
      "222611                      \"、\"白身\"，把缺乏锻炼、阅历不深的文人称作\"白面书生\"等   \n",
      "222612                      \"、\"白身\"，把缺乏锻炼、阅历不深的文人称作\"白面书生\"等   \n",
      "222613                      \"、\"白身\"，把缺乏锻炼、阅历不深的文人称作\"白面书生\"等   \n",
      "\n",
      "                                                       病句  语病类型  Unnamed: 3  \\\n",
      "0       做哲学上的价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同...  成分残缺         NaN   \n",
      "1       做哲学上的价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同...  成分残缺         NaN   \n",
      "2       做哲学上的价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同...  成分残缺         NaN   \n",
      "3       做上的价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同一个...  成分残缺         NaN   \n",
      "4       做哲学上的价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同...  成分残缺         NaN   \n",
      "...                                                   ...   ...         ...   \n",
      "222609      \"\"\"[20]（p.39）但随着研究的不断深入，学者们结论的得出也逐渐趋向比较客观和公允\"  语序不当         NaN   \n",
      "222610      \"\"\"[20]（p.39）学者但随着研究的不断深入，们得出的结论也逐渐趋向比较客观和公允\"  语序不当         NaN   \n",
      "222611                \"\"\"、\"\"白身\"\"，把为锻炼、阅历不深的文人称作\"\"白面书生\"\"等\"  成分残缺         NaN   \n",
      "222612               \"\"\"、\"\"白身\"\"，把缺乏锻炼、阅历不深的文人称作\"\"白面书生\"\"或\"  不合逻辑         NaN   \n",
      "222613               \"\"\"、\"\"白身\"\"，把缺乏锻炼、阅历不文人的深称作\"\"白面书生\"\"等\"  语序不当         NaN   \n",
      "\n",
      "       Unnamed: 4 Unnamed: 5  \n",
      "0             NaN        NaN  \n",
      "1             NaN        NaN  \n",
      "2             NaN        NaN  \n",
      "3             NaN        NaN  \n",
      "4             NaN        NaN  \n",
      "...           ...        ...  \n",
      "222609        NaN        NaN  \n",
      "222610        NaN        NaN  \n",
      "222611        NaN        NaN  \n",
      "222612        NaN        NaN  \n",
      "222613        NaN        NaN  \n",
      "\n",
      "[222614 rows x 6 columns]\n",
      "                                                     病句   语病类型  \\\n",
      "0     做哲学上的价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同...   句式杂糅   \n",
      "1     做哲学上的价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同...   句式杂糅   \n",
      "2     做哲学上的价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同...   句式杂糅   \n",
      "3     做上价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同一个问...   句式杂糅   \n",
      "4     做哲学上的价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同...   句式杂糅   \n",
      "...                                                 ...    ...   \n",
      "1024      作为传统语言文化得以传承的重要媒介而言，汉语言文学课程应当得到中职以及教师中职生的全面关注   语序不当   \n",
      "1025  作为传统文化的重要组成部分，茶文化是中华民族的知识共同体，因而能够良好地赢得人们的统一认识，...  表达不恰当   \n",
      "1026  作为传统文化的重要组成部分，茶文化是中华民族的知识共同体，因而能够很地赢得人们的统一认识，并...   语序不当   \n",
      "1027  作为传统文化的重要组成部分，茶文化是中华民族的知识共同体，因而能够很好地赢得的共同认识，并且...   搭配不当   \n",
      "1028  作为传统文化的重要组成部分，茶文化是中华民族的知识共同体，因而能够很好地赢得人们的统一认识，...   搭配不当   \n",
      "\n",
      "                                                   修正结果  \n",
      "0     做哲学上的价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同...  \n",
      "1     做哲学上的价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同...  \n",
      "2     做哲学上的价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同...  \n",
      "3     做上价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同一个问...  \n",
      "4     做哲学上的价值判断，每个人都是根据自己的标准来进行，判断的标准是因人而异的，甚至同一个人对同...  \n",
      "...                                                 ...  \n",
      "1024       作为传统语言文化得以传承的重要媒介，汉语言文学课程应当得到中职以及教师中职生的全面关注。  \n",
      "1025  作为传统文化的重要组成部分，茶文化是中华民族的知识共同体，因而能够良好地赢得人们的统一认识，...  \n",
      "1026  作为传统文化的重要组成部分，茶文化是中华民族的知识共同体，而且能够赢得人们的统一认识，并对人...  \n",
      "1027  作为传统文化的重要组成部分，茶文化是中华民族的共同认识，并且还可对人们的思想启发及升华发挥正...  \n",
      "1028  作为传统文化的重要组成部分，茶文化是中华民族的知识共同体，因而能够很好地赢得人们的统一认识，...  \n",
      "\n",
      "[1029 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1=pd.read_csv('dataset.csv',low_memory=False)\n",
    "print(df1)\n",
    "# for i in df1:\n",
    "#     print(i)\n",
    "# print(df1.keys)\n",
    "df2=pd.read_csv('resp.csv')\n",
    "print(df2)\n",
    "# for i in df2:\n",
    "    # print(i)\n",
    "df=pd.merge(df2,df1,on=\"病句\",how='left')\n",
    "df.to_csv('test.csv', encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "莫名其妙就能跑了。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "judging accuracy: 0.044487427466150864\n",
      "modifying cohesion: 0.0\n"
     ]
    }
   ],
   "source": [
    "with open('test.csv','r')as f:\n",
    "    judge_wrong=0\n",
    "    modify_wrong=0\n",
    "    tot_num=0\n",
    "    reader = csv.reader(f)\n",
    "    header=next(reader)\n",
    "    for row in reader:\n",
    "        if row[2]!=row[5]:\n",
    "            judge_wrong+=1\n",
    "        if row[3]!=row[4]:\n",
    "            modify_wrong+=1\n",
    "        tot_num+=1\n",
    "jug_acc=1-judge_wrong/tot_num\n",
    "mod_acc=1-modify_wrong/tot_num\n",
    "print(\"judging accuracy:\",jug_acc)\n",
    "print(\"modifying cohesion:\",mod_acc)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
